{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65bda451-6919-4a51-9147-f50e0209a283",
   "metadata": {},
   "source": [
    "# Generate Bbox definition for the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da909d15-1b0e-4476-a20a-0db1cce98a80",
   "metadata": {},
   "source": [
    "This notebook loads the USDA CDL dataset, and generates chip bbox across the CONUS to have a diverse distribution of classes. \n",
    "The notebook is designed for projects run at Clark University's Center for Geospatial Analytics; hence, it has certain features that are shared across multiple projects. For example, we merge all CDL classes to 13 classes before sampling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f05c11e-196d-434e-b2bc-4512413f7356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray \n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyproj\n",
    "import json\n",
    "from shapely.geometry import Polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ed7a86-7e2e-4310-86dd-f63ff3a4c34e",
   "metadata": {},
   "source": [
    "### Load CDL Data\n",
    "You need to download the CDL .tiff file from USDA' website [here](https://www.nass.usda.gov/Research_and_Science/Cropland/Release/index.php) and store it under `data/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f350978-2693-4ef9-905f-b74dd59e217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdl_class_df = pd.read_csv(\"data/cdl_classes.csv\", encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243ad12a-2287-4658-96e5-c1968d0b409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop class values that do not represent any real class (not all 256 values represent a class)\n",
    "cdl_class_valid = cdl_class_df[~cdl_class_df['value'].isna()][\"class\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c11d9f7-6145-4094-8010-91a9650433d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdl_file = \"data/2022_30m_cdls.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8a6a1d-6236-4d16-bb46-aa8043bf7f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "xds = rioxarray.open_rasterio(cdl_file, cache=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294c8842-e309-4c6e-9bdf-3eddddea914e",
   "metadata": {},
   "source": [
    "### Chipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3333ca0a-d81e-4436-a6d9-0fcbe1c64c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define chip specs\n",
    "chip_dim_x = 224\n",
    "chip_dim_y = 224\n",
    "x0 = xds.x.data[0]\n",
    "y0 = xds.y.data[0]\n",
    "res = 30 # meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8473856f-9be0-4fff-8325-5c9148ed5ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty df to load chips\n",
    "df_columns = [\"chip_id\"]\n",
    "df_columns.append(0)\n",
    "for i in cdl_class_df[\"class\"]:\n",
    "    df_columns.append(i)\n",
    "df_columns.append(\"chip_coordinate_x\")\n",
    "df_columns.append(\"chip_coordinate_y\")\n",
    "chips_df = pd.DataFrame(columns = df_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6f4603-d6f7-4b5e-9dcb-cd5ad3f790f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Iterate over non-overlapping chips across all of CONUS and load their properties into the df\n",
    "for idx in range(0, int(np.floor(xds.shape[2] / chip_dim_x))):\n",
    "    for idy in range(0, int(np.floor(xds.shape[1] / chip_dim_y))):\n",
    "        chip_id = f\"chip_{str(idy).zfill(3)}_{str(idx).zfill(3)}\"\n",
    "        chip_x0 = x0 + idx * chip_dim_x * res\n",
    "        chip_y0 = y0 - idy * chip_dim_y * res\n",
    "        # Note: the following line uses xarray da.sel() method which uses inclusive bounds for data selection. Hence\n",
    "        # we use (chip_dim_y -1) and (chip_dim_x -1). \n",
    "        chip = xds.rio.slice_xy(chip_x0, chip_y0 - (chip_dim_y -1) * res, chip_x0 + (chip_dim_x - 1) * res, chip_y0)\n",
    "        classes, class_counts = np.unique(chip.data, return_counts=True)\n",
    "        # Drop chips that contain no-data value (0)\n",
    "        if 0 not in classes: \n",
    "            counts = np.zeros(256)\n",
    "            counts[classes] = class_counts\n",
    "            chips_df.loc[len(chips_df.index)] = [chip_id] + counts.tolist() + [chip_x0, chip_y0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee32d6e-49e8-45b3-bee6-b99ff977dac7",
   "metadata": {},
   "source": [
    "### Inspect Data Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe60377-8e93-4a30-a9d2-32a313047529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of classes across the dataset. \n",
    "import matplotlib.pyplot as plt\n",
    "plt.bar(cdl_class_valid, chips_df.loc[:, cdl_class_valid].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9d02ad-4813-489f-a9a4-5fbe869357bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting total class distribution and define classes to merge. \n",
    "cdl_total_dst = pd.DataFrame(chips_df.loc[:, cdl_class_valid].sum(), columns=[\"total_count\"])\n",
    "cdl_total_dst[\"percentage\"] = cdl_total_dst[\"total_count\"] / cdl_total_dst[\"total_count\"].sum()\n",
    "cdl_total_dst.sort_values(by = \"percentage\", ascending = False, inplace = True)\n",
    "cdl_total_dst[\"cum_percentage\"] = cdl_total_dst[\"percentage\"].cumsum(axis = 0)\n",
    "cdl_total_dst[\"class_name\"] = np.nan\n",
    "for i in cdl_total_dst.iterrows():\n",
    "    cdl_total_dst.loc[i[0], \"class_name\"] = cdl_class_df[cdl_class_df[\"class\"] == i[0]][\"value\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3e9cbd-b101-44f1-bfc9-daff59a51c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do NOT uncomment this. This will overwrite the csv file which contains the column \"new_class_value\". \n",
    "# This column is added manually by inspecting the class distribution, and defines the new class values. \n",
    "# cdl_total_dst.to_csv('cdl_total_dst.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7391e3-dafe-4a6f-8020-29cc99966ced",
   "metadata": {},
   "source": [
    "Reviewed the csv manually, and defined new classes to merge. \n",
    "In the following we will load the csv again, and create a new df with new classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caffa62d-c823-4e72-ab8f-5818eeae5eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdl_total_dst = pd.read_csv(\"cdl_total_dst.csv\")\n",
    "n_classes = cdl_total_dst[\"new_class_value\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0472a8-729b-4503-a9d6-f484ece57f57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chips_df_to_sample = pd.DataFrame(np.zeros((chips_df.shape[0], n_classes)), columns = np.arange(1, n_classes+1))\n",
    "for row in cdl_total_dst.iterrows():\n",
    "    chips_df_to_sample.loc[:, row[1][\"new_class_value\"]] = chips_df_to_sample.loc[:, row[1][\"new_class_value\"]] + chips_df.loc[:, row[1][\"old_class_value\"]]\n",
    "chips_df_to_sample[\"chip_id\"] =  chips_df[\"chip_id\"]\n",
    "chips_df_to_sample[\"chip_coordinate_x\"] = chips_df[\"chip_coordinate_x\"]\n",
    "chips_df_to_sample[\"chip_coordinate_y\"] = chips_df[\"chip_coordinate_y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4002d4e8-5e4c-4bf9-9666-d09b0cffb9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following confirms that the re-classification (merging of similar classes hasn't resulted in any mistake). \n",
    "print(np.sum(chips_df_to_sample[[col for col in chips_df_to_sample.columns if col not in [\"chip_coordinate_y\", \"chip_coordinate_x\", \"chip_id\"]]].sum()))\n",
    "\n",
    "print(np.sum(chips_df[[col for col in chips_df.columns if col not in [\"chip_coordinate_y\", \"chip_coordinate_x\", \"chip_id\"]]].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629fb633-e727-4f91-bea8-cb7a66efaf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chips_df_to_sample.to_csv(\"chips_df_to_sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b467a1-3ea9-4105-b3fa-69f3a4c8c53a",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2f68b1-bf1a-4817-a762-771c8798cf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chip_weight(row):\n",
    "    \"\"\"\n",
    "        This function return a weight for each chip (defined as a row in the df). \n",
    "        The weight is 1 - the difference between the max and min of the portion of the chip that is covered \n",
    "        by each class. e.g. if the dominant class takes 0.5 of the chip area and the least dominant one takes 0.1\n",
    "        the weight would be 1 - (0.5 - 0.1). In this way, chips that have more even distribution get higher weight. \n",
    "        In addition to avoid having chips that only contain certain dominant classes, any chip with less than 8 classes\n",
    "        will be punished with a weight of zero. \n",
    "    \"\"\"\n",
    "    weight = 1 - (np.max(row) - np.min(row)) / np.sum(row)\n",
    "    if np.count_nonzero(row) < 8:\n",
    "        wegiht = weight - 1\n",
    "    if weight < 0:\n",
    "        weight = 0\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06af36fb-65f8-4527-8324-cc354c166f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "chips_df_to_sample[\"chip_weight\"] = chips_df_to_sample.loc[:, 1:n_classes].apply(chip_weight, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beacffe7-d294-4045-9ce7-7d32d0fa9821",
   "metadata": {},
   "outputs": [],
   "source": [
    "chips_df_to_sample[\"chip_weight\"] = chips_df_to_sample[\"chip_weight\"] / chips_df_to_sample[\"chip_weight\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7000d1e-af99-4b0b-887f-ad68c9e81820",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import choice\n",
    "samples = choice(chips_df_to_sample.index, 100000000, p = chips_df_to_sample[\"chip_weight\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c82c4fb-63d6-40d8-b40c-9dab457f9135",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqe_sample, sample_count = np.unique(samples, return_counts=True)\n",
    "sample_counts = np.zeros(chips_df_to_sample.index.shape)\n",
    "sample_counts[uniqe_sample] = sample_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a95a568-6a78-46b1-84c6-ba712b11d96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chips_df_to_sample['total_samples_count'] = sample_counts\n",
    "\n",
    "chips_df_to_sample.sort_values(by=['total_samples_count'], ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d09eaae-8384-4247-ba1d-bc876b2f5973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chips_df_to_sample.to_csv(\"chips_df_to_sample_sampled.csv\")\n",
    "chips_df_to_sample = pd.read_csv(\"chips_df_to_sample_sampled.csv\", index_col=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a05c892-1b01-4a7d-a315-65d2967516e1",
   "metadata": {},
   "source": [
    "### Generate BBoxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37773952-ea1a-432b-9633-a6ee2b14cb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.bar(range(1, n_classes+1), chips_df_to_sample.iloc[:10000, range(0, n_classes)].sum()/np.sum(chips_df_to_sample.iloc[:10000, range(0, n_classes)].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c7b726-3b28-49ca-ab24-d431d83b9af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(chips_df_to_sample.iloc[:10000, 17], chips_df_to_sample.iloc[:10000, 18], \"*\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f893ba8a-a499-4099-8036-67858b1f6ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "proj = pyproj.Transformer.from_crs(5070, 4326, always_xy=True)\n",
    "chip_height = chip_dim_y * res\n",
    "chip_width = chip_dim_x * res\n",
    "for row in chips_df_to_sample.iloc[:10000, :].iterrows():\n",
    "    feature_template = [{'type': 'Feature',\n",
    "                'properties': {'id': 0,\n",
    "                              'center': [0, 0]},\n",
    "                'geometry': {'type': 'MultiPolygon',\n",
    "                'coordinates': [[[[-281415, 1533615],\n",
    "                                  [256185, 1533615],\n",
    "                                  [256185, 996015],\n",
    "                                  [-281415, 996015],\n",
    "                                  [-281415, 1533615]]]]\n",
    "                            }\n",
    "               }]\n",
    "    # The subtraction/addition of `res` is needed in the following to change the x and y from center of the pixel to the edge\n",
    "    chip_x0 = row[1][\"chip_coordinate_x\"] - res / 2\n",
    "    chip_y0 = row[1][\"chip_coordinate_y\"] + res / 2\n",
    "\n",
    "    coor = [[[[proj.transform(chip_x0, chip_y0)[0], proj.transform(chip_x0, chip_y0)[1]],\n",
    "              [proj.transform(chip_x0, chip_y0 - chip_height)[0], proj.transform(chip_x0, chip_y0 - chip_height)[1]],\n",
    "              [proj.transform(chip_x0 + chip_width, chip_y0 - chip_height)[0], proj.transform(chip_x0 + chip_width, chip_y0 - chip_height)[1]],\n",
    "              [proj.transform(chip_x0 + chip_width, chip_y0)[0], proj.transform(chip_x0 + chip_width, chip_y0)[1]],\n",
    "              [proj.transform(chip_x0, chip_y0)[0], proj.transform(chip_x0, chip_y0)[1]]\n",
    "         ]]]\n",
    "    chip_cen = [chip_x0 + chip_width / 2, chip_y0 - chip_height / 2]\n",
    "    chip_cen_lon, chip_cen_lat = proj.transform(chip_cen[0], chip_cen[1])\n",
    "    \n",
    "    feature_template[0]['geometry']['coordinates'] = coor\n",
    "    feature_template[0]['properties']['id'] = row[1][\"chip_id\"]\n",
    "    feature_template[0]['properties']['center'] = [chip_cen_lon, chip_cen_lat] \n",
    "    features.extend(feature_template)\n",
    "\n",
    "feature_collection = {\n",
    "'type': 'FeatureCollection',\n",
    " 'name': 'chips',\n",
    " 'crs': {'type': 'name', 'properties': {'name': 'urn:ogc:def:crs:EPSG::4326'}},\n",
    " 'features': features\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ea2e60-c3cd-4fca-a171-52fcbd6d057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/chip_bbox_task_3.geojson\", 'w') as outfile:\n",
    "    json.dump(feature_collection, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6996ca06-2148-45f7-a258-8a8a063ca351",
   "metadata": {},
   "source": [
    "Generating the same geojson files but with coordinates in 5070 for chipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30442fc-b578-41d7-88c1-6ba00eaf5903",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "chip_height = chip_dim_y * res\n",
    "chip_width = chip_dim_x * res\n",
    "for row in chips_df_to_sample.iloc[:10000, :].iterrows():\n",
    "    feature_template = [{'type': 'Feature',\n",
    "                'properties': {'id': 0,\n",
    "                              'center': [0, 0]},\n",
    "                'geometry': {'type': 'MultiPolygon',\n",
    "                'coordinates': [[[[-281415, 1533615],\n",
    "                                  [256185, 1533615],\n",
    "                                  [256185, 996015],\n",
    "                                  [-281415, 996015],\n",
    "                                  [-281415, 1533615]]]]\n",
    "                            }\n",
    "               }]\n",
    "    # The subtraction/addition of `res` is needed in the following to change the x and y from center of the pixel to the edge\n",
    "    chip_x0 = row[1][\"chip_coordinate_x\"] - res / 2\n",
    "    chip_y0 = row[1][\"chip_coordinate_y\"] + res / 2\n",
    "\n",
    "    coor = [[[[chip_x0, chip_y0],\n",
    "              [chip_x0, chip_y0 - chip_height],\n",
    "              [chip_x0 + chip_width, chip_y0 - chip_height],\n",
    "              [chip_x0 + chip_width, chip_y0],\n",
    "              [chip_x0, chip_y0]\n",
    "         ]]]\n",
    "    chip_cen = [chip_x0 + chip_width / 2, chip_y0 - chip_height / 2]\n",
    "    chip_cen_lon, chip_cen_lat = [chip_cen[0], chip_cen[1]]\n",
    "    \n",
    "    feature_template[0]['geometry']['coordinates'] = coor\n",
    "    feature_template[0]['properties']['id'] = row[1][\"chip_id\"]\n",
    "    feature_template[0]['properties']['center'] = [chip_cen_lon, chip_cen_lat] \n",
    "    features.extend(feature_template)\n",
    "\n",
    "feature_collection = {\n",
    "'type': 'FeatureCollection',\n",
    " 'name': 'chips',\n",
    " 'crs': {'type': 'name', 'properties': {'name': 'urn:ogc:def:crs:EPSG::5070'}},\n",
    " 'features': features\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78903c75-184f-4991-b982-2a68812a262d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/chip_bbox_task_3_5070.geojson\", 'w') as outfile:\n",
    "    json.dump(feature_collection, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
